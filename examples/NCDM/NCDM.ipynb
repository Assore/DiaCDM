{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Cognitive Diagnosis Model (NCDM)\n",
    "This notebook will show you how to train and use the NCDM. First, we will show how to get the data (here we use a0910 as the dataset). Then we will show how to train a NCDM and perform the parameters persistence. At last, we will show how to load the parameters from the file and evaluate on the test dataset.\n",
    "\n",
    "The script version could be found in [NCDM.py](NCDM.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Before we process the data, we need to first acquire the dataset which is shown in this [prepare_dataset.ipynb](prepare_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:26:34.358055Z",
     "start_time": "2024-11-20T12:26:33.001465Z"
    }
   },
   "source": [
    "# Load the data from files\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/a0910/train.csv\")\n",
    "valid_data = pd.read_csv(\"../../data/a0910/valid.csv\")\n",
    "test_data = pd.read_csv(\"../../data/a0910/test.csv\")\n",
    "df_item = pd.read_csv(\"../../data/a0910/item.csv\")\n",
    "item2knowledge = {}\n",
    "knowledge_set = set()\n",
    "for i, s in df_item.iterrows():\n",
    "    item_id, knowledge_codes = s['item_id'], list(set(eval(s['knowledge_code'])))\n",
    "    item2knowledge[item_id] = knowledge_codes\n",
    "    knowledge_set.update(knowledge_codes)\n",
    "\n",
    "train_data.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user_id  item_id  score\n",
       "0     1615    12977      1\n",
       "1      782    13124      0\n",
       "2     1084    16475      0\n",
       "3      593     8690      0\n",
       "4      127    14225      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1615</td>\n",
       "      <td>12977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>782</td>\n",
       "      <td>13124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1084</td>\n",
       "      <td>16475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>14225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:26:37.480660Z",
     "start_time": "2024-11-20T12:26:37.470660Z"
    }
   },
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186049, 25606, 55760)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:26:40.410645Z",
     "start_time": "2024-11-20T12:26:40.403640Z"
    }
   },
   "source": [
    "# Get basic data info for model initialization\n",
    "import numpy as np\n",
    "user_n = np.max(train_data['user_id'])\n",
    "item_n = np.max([np.max(train_data['item_id']), np.max(valid_data['item_id']), np.max(test_data['item_id'])])\n",
    "knowledge_n = np.max(list(knowledge_set))\n",
    "\n",
    "user_n, item_n, knowledge_n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(4128), np.int64(17746), np.int64(123))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:26:45.901614Z",
     "start_time": "2024-11-20T12:26:43.942836Z"
    }
   },
   "source": [
    "# Transform data to torch Dataloader (i.e., batchify)\n",
    "# batch_size is set to 32\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "def transform(user, item, item2knowledge, score, batch_size):\n",
    "    knowledge_emb = torch.zeros((len(item), knowledge_n))\n",
    "    for idx in range(len(item)):\n",
    "        knowledge_emb[idx][np.array(item2knowledge[item[idx]]) - 1] = 1.0\n",
    "\n",
    "    data_set = TensorDataset(\n",
    "        torch.tensor(user, dtype=torch.int64) - 1,  # (1, user_n) to (0, user_n-1)\n",
    "        torch.tensor(item, dtype=torch.int64) - 1,  # (1, item_n) to (0, item_n-1)\n",
    "        knowledge_emb,\n",
    "        torch.tensor(score, dtype=torch.float32)\n",
    "    )\n",
    "    return DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_set, valid_set, test_set = [\n",
    "    transform(data[\"user_id\"], data[\"item_id\"], item2knowledge, data[\"score\"], batch_size)\n",
    "    for data in [train_data, valid_data, test_data]\n",
    "]\n",
    "\n",
    "train_set, valid_set, test_set"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\61489\\AppData\\Local\\Temp\\ipykernel_15732\\3283926272.py:9: UserWarning: Failed to initialize NumPy: DLL load failed while importing _multiarray_umath: 找不到指定的模块。 (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  knowledge_emb = torch.zeros((len(item), knowledge_n))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 22\u001B[0m\n\u001B[0;32m     13\u001B[0m     data_set \u001B[38;5;241m=\u001B[39m TensorDataset(\n\u001B[0;32m     14\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtensor(user, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# (1, user_n) to (0, user_n-1)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtensor(item, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# (1, item_n) to (0, item_n-1)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m         knowledge_emb,\n\u001B[0;32m     17\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtensor(score, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     18\u001B[0m     )\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataLoader(data_set, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 22\u001B[0m train_set, valid_set, test_set \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     23\u001B[0m     transform(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m\"\u001B[39m], data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mitem_id\u001B[39m\u001B[38;5;124m\"\u001B[39m], item2knowledge, data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m], batch_size)\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m [train_data, valid_data, test_data]\n\u001B[0;32m     25\u001B[0m ]\n\u001B[0;32m     27\u001B[0m train_set, valid_set, test_set\n",
      "Cell \u001B[1;32mIn[4], line 23\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     13\u001B[0m     data_set \u001B[38;5;241m=\u001B[39m TensorDataset(\n\u001B[0;32m     14\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtensor(user, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# (1, user_n) to (0, user_n-1)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtensor(item, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# (1, item_n) to (0, item_n-1)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m         knowledge_emb,\n\u001B[0;32m     17\u001B[0m         torch\u001B[38;5;241m.\u001B[39mtensor(score, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     18\u001B[0m     )\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataLoader(data_set, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     22\u001B[0m train_set, valid_set, test_set \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m---> 23\u001B[0m     \u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mitem_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem2knowledge\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m [train_data, valid_data, test_data]\n\u001B[0;32m     25\u001B[0m ]\n\u001B[0;32m     27\u001B[0m train_set, valid_set, test_set\n",
      "Cell \u001B[1;32mIn[4], line 11\u001B[0m, in \u001B[0;36mtransform\u001B[1;34m(user, item, item2knowledge, score, batch_size)\u001B[0m\n\u001B[0;32m      9\u001B[0m knowledge_emb \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(item), knowledge_n))\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(item)):\n\u001B[1;32m---> 11\u001B[0m     knowledge_emb[idx][np\u001B[38;5;241m.\u001B[39marray(item2knowledge[item[idx]]) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n\u001B[0;32m     13\u001B[0m data_set \u001B[38;5;241m=\u001B[39m TensorDataset(\n\u001B[0;32m     14\u001B[0m     torch\u001B[38;5;241m.\u001B[39mtensor(user, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# (1, user_n) to (0, user_n-1)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     torch\u001B[38;5;241m.\u001B[39mtensor(item, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint64) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,  \u001B[38;5;66;03m# (1, item_n) to (0, item_n-1)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     knowledge_emb,\n\u001B[0;32m     17\u001B[0m     torch\u001B[38;5;241m.\u001B[39mtensor(score, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataLoader(data_set, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Could not infer dtype of numpy.int64"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:26:57.224788Z",
     "start_time": "2024-11-20T12:26:56.103951Z"
    }
   },
   "source": [
    "from EduCDM import NCDM\n",
    "\n",
    "cdm = NCDM(knowledge_n, item_n, user_n)\n",
    "cdm.train(train_set, valid_set, epoch=3, device=\"cuda\")\n",
    "cdm.save(\"ncdm.snapshot\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mEduCDM\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NCDM\n\u001B[0;32m      3\u001B[0m cdm \u001B[38;5;241m=\u001B[39m NCDM(knowledge_n, item_n, user_n)\n\u001B[1;32m----> 4\u001B[0m cdm\u001B[38;5;241m.\u001B[39mtrain(\u001B[43mtrain_set\u001B[49m, valid_set, epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m cdm\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mncdm.snapshot\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from ncdm.snapshot\n",
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 1743/1743 [00:02<00:00, 763.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.751848, accuracy: 0.730273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cdm.load(\"ncdm.snapshot\")\n",
    "auc, accuracy = cdm.eval(test_set)\n",
    "print(\"auc: %.6f, accuracy: %.6f\" % (auc, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
